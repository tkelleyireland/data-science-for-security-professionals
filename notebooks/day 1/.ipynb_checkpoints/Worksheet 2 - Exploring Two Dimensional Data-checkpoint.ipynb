{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../img/logo_white_bkg_small.png\" align=\"left\" /> \n",
    "# Worksheet 2:  Exploring Two Dimensional Data\n",
    "This worksheet covers concepts covered in the second half of Module 1 - Exploratory Data Analysis in Two Dimensions.  It should take no more than 20-30 minutes to complete.  Please raise your hand if you get stuck.  \n",
    "\n",
    "There are many ways to accomplish the tasks that you are presented with, however you will find that by using the techniques covered in class, the exercises should be relatively simple. \n",
    "\n",
    "## Import the Libraries\n",
    "For this exercise, we will be using:\n",
    "* Pandas (http://pandas.pydata.org/pandas-docs/stable/)\n",
    "* Numpy (https://docs.scipy.org/doc/numpy/reference/)\n",
    "* Matplotlib (http://matplotlib.org/api/pyplot_api.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Reading various forms of JSON Data\n",
    "In the `/data/` folder, you will find a series of `.json` files called `dataN.json`, numbered 1-4.  Each file contains the following data:\n",
    "\n",
    "\n",
    "| |birthday\t| first_name |last_name |\n",
    "|--|-----------|------------|----------|\n",
    "|0\t|5\\/3\\/67\t|Robert\t|Hernandez |\n",
    "|1\t|8\\/4\\/84\t|Steve\t|Smith |\n",
    "|2\t|9\\/13\\/91\t|Anne\t|Raps |\n",
    "|3\t|4\\/15\\/75\t|Alice\t|Muller |\n",
    "\n",
    "Using the `.read_json()` function and the various configuration options, read all these files into a dataframe.  The documentation is available here: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_json.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: \n",
    "In the data file, there is a webserver file called `hackers-access.httpd`.  For this exercise, you will use this file to answer the following questions:\n",
    "1.  Which browsers are the top 10 most used browsers in this data?\n",
    "2.  Which are the top 10 most used operating systems?\n",
    "\n",
    "In order to accomplish this task, do the following:\n",
    "1.  Write a function which takes a User Agent string as an argument and returns the relevant data.  HINT:  You might want to use python's `user_agents` module, the documentation for which is available here: (https://pypi.python.org/pypi/user-agents)\n",
    "2.  Next, apply this function to the column which contains the user agent string.\n",
    "3.  Store this series as a new column in the dataframe\n",
    "4.  Count the occurances of each value in the new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_log_parser\n",
    "from user_agents import parse\n",
    "#Read in the log file\n",
    "line_parser = apache_log_parser.make_parser(\"%h %l %u %t \\\"%r\\\" %>s %b \\\"%{Referer}i\\\" \\\"%{User-agent}i\\\"\")\n",
    "\n",
    "server_log = open(\"../data/hackers-access.httpd\", \"r\")\n",
    "parsed_server_data = []\n",
    "for line in server_log:\n",
    "    data = {}\n",
    "    data = line_parser(line)\n",
    "    parsed_server_data.append( data )\n",
    "\n",
    "server_df = pd.DataFrame( parsed_server_data  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write the functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the functions to the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the top 10 values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3:\n",
    "Using the `dailybots.csv` film, read the file into a DataFrame and perform the following operations:\n",
    "1.  Filter the DataFrame to include bots from the Government/Politics Industry.\n",
    "2.  Calculate the ratio of hosts to orgs and add this as a column to the DataFrame and output the result\n",
    "3.  Calculate the total number of hosts infected by each BotFam in the Government/Politics Industry.  You should use the `groupby()` function which is documented here: (http://pandas.pydata.org/pandas-docs/stable/groupby.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
